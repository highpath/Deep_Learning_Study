{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Nature Deep Review.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPzIyjy7GzY5zG9z6IYwBST"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_vXpn6CQAlsf","colab_type":"text"},"source":["# LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \"Deep learning.\" Nature 521.7553 (2015): 436-444\n","\n","http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf"]},{"cell_type":"markdown","metadata":{"id":"VNAsT4t0A_x3","colab_type":"text"},"source":["## 서문\n","\n","Deep learning은 Multiple processing layers로 이루어진 컴퓨터 모델들을 가능하게 합니다. 그것들은 추상적인 여러 단계의 데이터의 Representations를 배울 수 있습니다. 이런 방법들은 현재 활발한 연구 중에 있는 Speech recognition, Visual object recognition, Object detection, 그리고 Drug discovery나 Genomics 같은 여러 분야를 큰 폭으로 발전시켜 왔습니다. Deep learning은 Backpropagtion algorithm을 사용해 많은 데이터에서 내재된 구조를 발견합니다. Backpropagation algorith은 기계가 각 층의 Representation을 계산하기 위해 사용되는 내재된 변수들을 어떻게 바꿔야 하는지 알려줍니다. Deep convolutional nets는 images, video, speech, 그리고 audio를 처리하는데 엄청난 발전을 가져왔습니다. 반면 Recurrent nets는 Text나 Speech 같은 Sequential data에 빛을 비췄습니다."]},{"cell_type":"markdown","metadata":{"id":"mhii5l5gEIT0","colab_type":"text"},"source":["## 본문1\n","\n","1. 머신러닝의 영향력\n","2. 전통적인 머신러닝 기법들의 한계\n","    - 특정 분야에 대한 전문적인 지식과 데이터에 대한 세밀한 가공, 처리가 필요했다.\n","3. Representation Learning과 Deep Learning\n","    - Representation Learning이란 인식이나 분류에 필요한 Representations를 Raw Data로부터 자동적으로 발견하는 기법이다. Deep Learning 기법은 간단하지만 비선형적인 모듈로부터 얻어지는 여러 단계의 Representation을 이용하는 Representation Learning이라 할 수 있다. 모듈은 입력받은 representaion을 raw data에서 시작해 더 높은, 더 추상적인 단계의 representation으로 변환한다. 충분한 단계의 변형이 이루어지면, 매우 복잡한 문제도 해결할 수 있게 되는 것이다. 분류 작업에서는, 고층의 representation은 input에서 분류에 필요한 면을 극대화하고, 무관한 변수들은 억제한다. *(Image의 사례).* Deep Learning의 주요한 면은 이런 여러 층의 특징을 사람이 만드는 것이 아니라 일반적인 목적을 가진 학습 단계를 거친 데이터로부터 얻어진다는 것이다.\n","4. Deep Learning의 영향력\n","5. Deep Learning의 유망성"]},{"cell_type":"markdown","metadata":{"id":"AKl0O1f6QxlW","colab_type":"text"},"source":["## 본문2: Supervised learning\n","\n","1. Supervised Learning\n","    - machine learning의 가장 일반적인 형태는 지도 학습이다. 전통적인 deep-learning 시스템에서는, \n","2. 적절하게 weight vector 적용하는 법\n","    - Learning Algorithm은 각 weight vector마다 gradient vector를 계산한다. Gradient Vector는 weight가 약간 증가하면 error가 어느 정도로 증가하거나 감소할 지를 나타낸다. weight vector는 gradient vector의 반대방향으로 적용된다.\n","3. \n","    - 모든 훈련 예제를 평균내는 목적 함수는 weight 값이 존재하는 고차원 공간에서의 언덕이 많은 풍경이라 할 수 있다. 음수의 gradient vector는 가파른 경사의 방향을 의미하고, error가 평균적으로 낮은 minimum에 가깝게 한다.\n","4. \n","대부분 stochastic gradient descent(SGD)이라는 방식을 이용한다. \n","5. \n","6. \n","7. "]},{"cell_type":"markdown","metadata":{"id":"jAw2suKuS2y-","colab_type":"text"},"source":["## 본문3: Backpropagation to train multilayer architectures\n","\n","1. 패턴 인식 연구의 초기부터, 연구자들의 목표는 직접 가공한 features를 학습가능한 multilayer network로 대체하는 것이었다. 하지만 그 간단함에도 불구하고, 그 방법은 1980년대 중반 까지 받아들여지지 않았다. 알려진대로, multilayer architectures는 간단한 stochastic gradient descent 방법으로 학습될 수 있다. input과 내재된 가중치의 함들이 상대적으로 부드러운 한, Backpropagation procedure을 사용해 기울기를 계산할 수 있다. 이게 가능하다는 생각은 1970년대, 1980년대 동안 여러 다른 그룹들에 의해 독립적으로 발견되었다.\n","\n","2. Backpropagation procedure을 이용해 가중치에 따른 목적함수의 기울기를 계산하는 것은 미분의 Chain Rule을 실제 적용한 것에 불과하다. input에 따른 목적함수의 기울기는 module의 결과로 부터 나오는 기울기를 반대로 계산해서 구할 수 있다. (Fig1). Backpropagation equation은 전체 modules에 gradients를 전파하기 위해 반복적으로 적용될 수 있다. 한 번 이 gradients가 계산되고 나면, weight에 따른 gradients를 정방향으로 계산한다.\n","\n","3. 딥러닝을 적용하는 많은 사례가 정해진 크기의 input과 정해진 크기의 output에 매핑하는 법을 학습하는 feedforward neural network 구조를 사용한다. 한 층에서 다음으로 가기 위해, units들은 전층으로부터 입력된 input의 가중치 합을 계산하고 non-linear function을 거친 결과를 넘긴다. 현재, 가장 유명한 non-linear 함수는 rectified linear unit(ReLU)다. ReLU는 half-wave rectifier f(z) = max(z,0)를 간단히 한 것이다. 몇십년 전에는 neural nets는 tanh(z) or 1/(1+exp(-z))같은 더 부드러운 non-linearities를 사용했다. 하지만 전형적으로 ReLU가 많은 층이 있는 network에서 훨씬 빠르게 학습해 unsupervised pre-training 없이 deep supervised network의 훈련을 가능하게 한다. input이나 output 층이 아닌 unit들은 전통적으로 hidden units라 불린다. hidden layers는 input을 non-linear한 방법으로 왜곡해 선형적으로 분리 가능하게 만든다고 볼 수도 있다.\n","\n","4. 1990년대 후반, neural nets과 backpropagation의 버려짐\n","    - 특히 좋지 않은 local minima에 빠지는 것에 대한 생각 때문에.\n","\n","5. local minima에 빠지는 것은 일반적으로 큰 문제가 아니다.\n","    - 실제로 좋지 않은 local minima은 large network에서 거의 문제가 되지 않는다. 초기의 조건과 상관없이, 매우 비슷한 질로 solution에 도달한다. 최근의 이론적, 실험적 결과들이 local minima가 일반적으로 큰 문제가 아님을 뒷받침해주고 있다. 분석은 \n","\n","6. 2006년대 초, deep feedforward networks에 대한 관심이 다시 살아났다.\n","    - CIFAR(Canadian Institute for Advanced Research) 연구자들이 labelled data의 필요 없이 feature의 층을 알아서 만드는 비지도 학습을 소개했다. 각각의 feature detector의 층을 학습하는 목적은 층들 아래 있는 feature detectors의 활동을 재구성할 수 있게 하는 것이었다. 몇몇층을 꾸준히 이 재구성 객체를 사용해서 'pre-training'함으로써, deep network의 weight들을 더 좋은 값으로 설정할 수 있었다. 이것은 handwritten digits, detecting pedestrians를 인식하는데, 특히 labelled data가 상당히 부족할 때 매우 잘 작동하였다.\n","\n","7. 이 pre-training 접근을 처음으로 주요하게 적용한 것은 speech recognition 분야이다. 그리고 그것은 빠른 GPUs(Graphics Processing Units)의 발전 덕분이었다. 2009년에 이 접근은 ~. 2012년까지, \n","\n","결국 small data sets을 위한 건 pre-training\n","\n","8. ConvNet\n","    - 하지만, 근접 층끼리 full connectivity를 가진 network보다 더 쉽게 학습하고 저 잘 일반화하는 타입의 deep, feedforward network가 있었다. 그것은 바로 ConvNet이다. ConvNet은 neural network가 소외된 동안 많은 실질적 성공을 이루었고 지금까지 computer vision community에서 널리 채택되고 있다."]},{"cell_type":"markdown","metadata":{"id":"gcRUwQhBgxMx","colab_type":"text"},"source":["![Multilayer neural networks and backpropagation_a](https://github.com/highpath/Deep_Learning_Study/blob/master/Papers/BackPropagation_a.PNG?raw=true)\n","\n","a. multilayer neural network는 데이터를 선형적으로 분리가능하도록 input space를 왜곡시킬 수 있다. 보기는 input unit 2개, hidden unit 2개, output unit 1개로 이루어져 있지만, 객체 인식이나 자연어 처리에 사용되는 네트워크는 수만에서 수십만개 unit을 가지고 있다. (http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)"]},{"cell_type":"markdown","metadata":{"id":"TTEdyvCTEbcv","colab_type":"text"},"source":["![Multilayer neural networks and backpropagation_b](https://github.com/highpath/Deep_Learning_Study/blob/master/Papers/Backpropagation_b.PNG?raw=true)\n","\n","b. Chain "]},{"cell_type":"markdown","metadata":{"id":"KV_DS0j7dqOM","colab_type":"text"},"source":["## 본문4: Convolutional neural networks\n","\n","1. local connections, shared weights, pooling and the use of many layers\n","2. 전형적인 ConvNet은 일련의 단계 형태로 구성되어 있다. 처음 몇 단계는 convolutional layers와 pooling layers로 구성되어 있다. convolutional layer의 기본단위는 feature maps로 구성되어 있다. 이는 filter bank라 불리는 가중치의 집합을 통해 연결된다. 이 local weighted sum의 결과는 ReLU 같은 non-linearity를 거친다. 하나의 feature map 안에 모든 units은 같은 filter bank를 공유한다. 한 층의 서로다른 feature maps는 다른 filter banks를 사용한다. 이 구조를 사용하는 이유는 두 가지다. 첫째로, 이미지 같은 array data에서는 값의 지역적 그룹들이 긴밀하게 연결되어 있어 쉽게 감지되는 local motifs를 형성한다. 두번째로, 이미지나 다른 신호의 지역 통계가 위치에 따라 다르지 않다는 것이다. 즉, 만약 motif가 이미지의 한 부분에서 나타났다면, 그것은 어디에서나 나타날 수 있다. 따라서 다른 위치에 같은 가중치를 공유하고 같은 패턴을 감지하는 것이다.\n","3. pooling layer\n","    - pooling layer의 역할은 의미적으로 비슷한 특징을 하나로 합치는 것이다. 하나의 motif를 형성하고 있는 features의 상대적 위치가 다양할 수 있으므로, 각 feature의 위치를 대략적으로 모으는 게 motif를 신뢰성있게 감지하는 것을 도와줄 수 있다. 전형적인 pooling unit은 local patch에서 maximum 값을 계산한다. 근처의 pooling units는 한 row나 column 넘게 이동한 patches로부터 input을 받기 때문에, 표현의 차원을 줄인다.\n","4. \n","5. \n","6. "]},{"cell_type":"markdown","metadata":{"id":"aLVeZIrgfPMY","colab_type":"text"},"source":["## 본문5: Image understanding with deep convolutional networks\n","\n","1. \n","2. "]},{"cell_type":"markdown","metadata":{"id":"WZw2_eaXfVM5","colab_type":"text"},"source":["## 본문6: Distributed representations and language processing\n","\n","1. \n","2. \n","3. \n","4. "]},{"cell_type":"markdown","metadata":{"id":"ELy2GqBIfc1j","colab_type":"text"},"source":["## 본문7: Recurrent neural networks\n","\n","1. \n","2. \n"]},{"cell_type":"markdown","metadata":{"id":"vMR9Pcp2fliL","colab_type":"text"},"source":["## 본문8: The future of deep learning"]}]}